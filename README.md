# CSE598_AcceleratingAI
## ðŸ“‚ List of Papers

1. **LMQL** - [Prompting Is Programming: A Query Language for Large Language Models](LINK_PLACEHOLDER_1) (2022)
2. **DSPy** - [DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines](LINK_PLACEHOLDER_2) (2023)
3. **DSPy** - [Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs](LINK_PLACEHOLDER_3) (2024)
4. **DSPy** - [GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning](LINK_PLACEHOLDER_4) (2025)
5. **SGLang** - [SGLang: Efficient Execution of Structured Language Model Programs](LINK_PLACEHOLDER_5) (2023)
6. **MTP** - [Meaning-Typed Programming: Language Abstraction and Runtime for Model-Integrated Applications](LINK_PLACEHOLDER_6) (2025)
7. **Apache TVM** - [TVM: An Automated End-to-End Optimizing Compiler for Deep Learning](LINK_PLACEHOLDER_7) (2018)
8. **Apache TVM** - [Relay: A High-Level Compiler for Deep Learning](LINK_PLACEHOLDER_8) (2019)
9. **Apache TVM** - [Ansor: Generating High-Performance Tensor Programs for Deep Learning](LINK_PLACEHOLDER_9) (2020)
10. **PyTorch 2** - [PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode and Graph Compilation for DNNs](LINK_PLACEHOLDER_10) (2024)
11. **PyTorch 2** - [TorchBench: Benchmarking PyTorch with High API Surface Coverage](LINK_PLACEHOLDER_11) (2023)
12. **PyTorch 2** - [TorchTitan: One-stop PyTorch native solution for production ready LLM pretraining](LINK_PLACEHOLDER_12) (2024)
13. **PyTorch ROCm** - [ECLIP: Energy-efficient and Practical Co-Location of ML Inference Pipelines on GPUs](LINK_PLACEHOLDER_13) (2025)
14. **Triton** - [Triton: An Intermediate Language and Compiler for Tiled Neural Network Computations](LINK_PLACEHOLDER_14) (2019)
15. **Triton** - [Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks](LINK_PLACEHOLDER_15) (2025)
16. **OpenXLA** - [Operator Fusion in XLA: Analysis and Evaluation](LINK_PLACEHOLDER_16) (2023)
17. **OpenXLA** - [Memory Safe Computations with XLA Compiler](LINK_PLACEHOLDER_17) (2022)
18. **Google MLIR** - [MLIR: A Compiler Infrastructure for the End of Moore's Law](LINK_PLACEHOLDER_18) (2020)
19. **Meta Glow** - [Glow: Graph Lowering Compiler Techniques for Neural Networks](LINK_PLACEHOLDER_19) (2018)
20. **vLLM** - [Efficient Memory Management for Large Language Model Serving with PagedAttention](LINK_PLACEHOLDER_20) (2023)
21. **vLLM** - [Effective Memory Management for Serving LLM with Heterogeneity](LINK_PLACEHOLDER_21) (2025)
22. **GPU ISA & Architecture** - [Demystifying the Nvidia Ampere Architecture through Microbenchmarking and Instruction-level Analysis](LINK_PLACEHOLDER_22) (2023)
23. **GPU ISA & Architecture** - [Cambricon: An Instruction Set Architecture for Neural Networks](LINK_PLACEHOLDER_23) (2016)
24. **CUDA/ROCm** - [Optimizing sDTW for AMD GPUs](LINK_PLACEHOLDER_24) (2024)
25. **TPU ISA & Architecture** - [TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings](LINK_PLACEHOLDER_25) (2023)
26. **TPU ISA & Architecture** - [MTIA: First Generation Silicon Targeting Meta's Recommendation Systems](LINK_PLACEHOLDER_26) (2023)
27. **TPU ISA & Architecture** - [Machine Learning Fleet Efficiency: Analyzing and Optimizing Large-Scale Google TPU Systems with ML Productivity Goodput](LINK_PLACEHOLDER_27) (2016)
28. **OpenVINO** - [OpenVINO Deep Learning Workbench: Comprehensive Analysis and Tuning of Neural Networks Inference](LINK_PLACEHOLDER_28) (2019)
29. **OpenVINO** - [Leveraging Speculative Sampling and KV-Cache Optimizations Together for Generative AI using OpenVINO](LINK_PLACEHOLDER_29) (2023)
30. **Intel PlaidML** - [Stripe: Tensor Compilation via the Nested Polyhedral Model](LINK_PLACEHOLDER_30) (2019)


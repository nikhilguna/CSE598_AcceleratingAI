# CSE598_AcceleratingAI
## ðŸ“‚ List of Papers

| Paper Name | Paper Link | GPT Summary Link |
|------------|------------|------------------|
| Prompting Is Programming: A Query Language for Large Language Models (2022) | [Link](PAPER_LINK_1) | [Summary](GPT_SUMMARY_LINK_1) |
| DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines (2023) | [Link](PAPER_LINK_2) | [Summary](GPT_SUMMARY_LINK_2) |
| Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs (2024) | [Link](PAPER_LINK_3) | [Summary](GPT_SUMMARY_LINK_3) |
| GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning (2025) | [Link](PAPER_LINK_4) | [Summary](GPT_SUMMARY_LINK_4) |
| SGLang: Efficient Execution of Structured Language Model Programs (2023) | [Link](PAPER_LINK_5) | [Summary](GPT_SUMMARY_LINK_5) |
| Meaning-Typed Programming: Language Abstraction and Runtime for Model-Integrated Applications (2025) | [Link](PAPER_LINK_6) | [Summary](GPT_SUMMARY_LINK_6) |
| TVM: An Automated End-to-End Optimizing Compiler for Deep Learning (2018) | [Link](PAPER_LINK_7) | [Summary](GPT_SUMMARY_LINK_7) |
| Relay: A High-Level Compiler for Deep Learning (2019) | [Link](PAPER_LINK_8) | [Summary](GPT_SUMMARY_LINK_8) |
| Ansor: Generating High-Performance Tensor Programs for Deep Learning (2020) | [Link](PAPER_LINK_9) | [Summary](GPT_SUMMARY_LINK_9) |
| PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode and Graph Compilation for DNNs (2024) | [Link](PAPER_LINK_10) | [Summary](GPT_SUMMARY_LINK_10) |
| TorchBench: Benchmarking PyTorch with High API Surface Coverage (2023) | [Link](PAPER_LINK_11) | [Summary](GPT_SUMMARY_LINK_11) |
| TorchTitan: One-stop PyTorch native solution for production ready LLM pretraining (2024) | [Link](PAPER_LINK_12) | [Summary](GPT_SUMMARY_LINK_12) |
| ECLIP: Energy-efficient and Practical Co-Location of ML Inference Pipelines on GPUs (2025) | [Link](PAPER_LINK_13) | [Summary](GPT_SUMMARY_LINK_13) |
| Triton: An Intermediate Language and Compiler for Tiled Neural Network Computations (2019) | [Link](PAPER_LINK_14) | [Summary](GPT_SUMMARY_LINK_14) |
| Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks (2025) | [Link](PAPER_LINK_15) | [Summary](GPT_SUMMARY_LINK_15) |
| Operator Fusion in XLA: Analysis and Evaluation (2023) | [Link](PAPER_LINK_16) | [Summary](GPT_SUMMARY_LINK_16) |
| Memory Safe Computations with XLA Compiler (2022) | [Link](PAPER_LINK_17) | [Summary](GPT_SUMMARY_LINK_17) |
| MLIR: A Compiler Infrastructure for the End of Moore's Law (2020) | [Link](PAPER_LINK_18) | [Summary](GPT_SUMMARY_LINK_18) |
| Glow: Graph Lowering Compiler Techniques for Neural Networks (2018) | [Link](PAPER_LINK_19) | [Summary](GPT_SUMMARY_LINK_19) |
| Efficient Memory Management for Large Language Model Serving with PagedAttention (2023) | [Link](PAPER_LINK_20) | [Summary](GPT_SUMMARY_LINK_20) |
| Effective Memory Management for Serving LLM with Heterogeneity (2025) | [Link](PAPER_LINK_21) | [Summary](GPT_SUMMARY_LINK_21) |
| Demystifying the Nvidia Ampere Architecture through Microbenchmarking and Instruction-level Analysis (2023) | [Link](PAPER_LINK_22) | [Summary](GPT_SUMMARY_LINK_22) |
| Cambricon: An Instruction Set Architecture for Neural Networks (2016) | [Link](PAPER_LINK_23) | [Summary](GPT_SUMMARY_LINK_23) |
| Optimizing sDTW for AMD GPUs (2024) | [Link](PAPER_LINK_24) | [Summary](GPT_SUMMARY_LINK_24) |
| TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings (2023) | [Link](PAPER_LINK_25) | [Summary](GPT_SUMMARY_LINK_25) |
| MTIA: First Generation Silicon Targeting Meta's Recommendation Systems (2023) | [Link](PAPER_LINK_26) | [Summary](GPT_SUMMARY_LINK_26) |
| Machine Learning Fleet Efficiency: Analyzing and Optimizing Large-Scale Google TPU Systems with ML Productivity Goodput (2016) | [Link](PAPER_LINK_27) | [Summary](GPT_SUMMARY_LINK_27) |
| OpenVINO Deep Learning Workbench: Comprehensive Analysis and Tuning of Neural Networks Inference (2019) | [Link](PAPER_LINK_28) | [Summary](GPT_SUMMARY_LINK_28) |
| Leveraging Speculative Sampling and KV-Cache Optimizations Together for Generative AI using OpenVINO (2023) | [Link](PAPER_LINK_29) | [Summary](GPT_SUMMARY_LINK_29) |
| Stripe: Tensor Compilation via the Nested Polyhedral Model (2019) | [Link](PAPER_LINK_30) | [Summary](GPT_SUMMARY_LINK_30) |


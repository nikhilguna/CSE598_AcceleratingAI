# CSE598_AcceleratingAI
## ðŸ“‚ List of Papers

| # | Technology Category | Paper Title | Year | Link | ChatGPT Log
|:--:|:------------------|:-------------|:----:|:-----|
| 1 | **LMQL** | **Prompting Is Programming: A Query Language for Large Language Models** | 2022 | [Paper](https://arxiv.org/abs/2212.06094) |
| 2 | **DSPy** | **DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines** | 2023 | [DSPy](https://arxiv.org/pdf/2310.03714) |
| 3 | **DSPy** | **Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs** | 2024 | [Paper](https://arxiv.org/abs/2406.11695) |
| 4 | **DSPy** | **GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning** | 2025 | [GEPA](https://arxiv.org/abs/2507.19457) |
| 5 | **SGLang** | **SGLang: Efficient Execution of Structured Language Model Programs** | 2023 | [Paper](https://arxiv.org/abs/2312.07104) |
| 6 | **MTP** | **Meaning-Typed Programming: Language Abstraction and Runtime for Model-Integrated Applications** | 2025 | [MTP](https://arxiv.org/abs/2405.08965) |
| 7 | **Apache TVM** | **TVM: An Automated End-to-End Optimizing Compiler for Deep Learning** | 2018 | [TVM](https://arxiv.org/abs/1802.04799) |
| 8 | **Apache TVM** | **Relay: A High-Level Compiler for Deep Learning** | 2019 | [Relay](https://arxiv.org/abs/1904.08368) |
| 9 | **Apache TVM** | **Ansor: Generating High-Performance Tensor Programs for Deep Learning** | 2020 | [Ansor](https://arxiv.org/abs/2006.06762) |
| 10 | **PyTorch 2** | **PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode and Graph Compilation for DNNs** | 2024 | [Pytorch2](https://dl.acm.org/doi/10.1145/3620665.3640366) |
| 11 | **PyTorch 2** | **TorchBench: Benchmarking PyTorch with High API Surface Coverage** | 2023 | [TorchBench](https://arxiv.org/abs/2304.14226) |
| 12 | **PyTorch 2** | **TorchTitan: One-stop PyTorch native solution for production ready LLM pretraining** | 2024 | [TorchTitan](https://arxiv.org/abs/2410.06511) |
| 13 | **PyTorch ROCm** | **ECLIP: Energy-efficient and Practical Co-Location of ML Inference Pipelines on GPUs** | 2025 | [ECLIP](https://arxiv.org/abs/2506.12598) |
| 14 | **Triton** | **Triton: An Intermediate Language and Compiler for Tiled Neural Network Computations** | 2019 | [Triton](https://dl.acm.org/doi/10.1145/3315508.3329973) |
| 15 | **Triton** | **Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks** | 2025 | [Geak](https://arxiv.org/abs/2507.23194) |
| 16 | **OpenXLA** | **Operator Fusion in XLA: Analysis and Evaluation** | 2023 | [OpFusion](https://arxiv.org/abs/2301.13062) |
| 17 | **OpenXLA** | **Memory Safe Computations with XLA Compiler** | 2022 | [MemSafeXLA](https://arxiv.org/abs/2206.14148) |
| 18 | **Google MLIR** | **MLIR: A Compiler Infrastructure for the End of Moore's Law** | 2020 | [MLIR](https://arxiv.org/abs/2002.11054) |
| 19 | **Meta Glow** | **Glow: Graph Lowering Compiler Techniques for Neural Networks** | 2018 | [Glow](https://arxiv.org/abs/1805.00907) |
| 20 | **vLLM** | **Efficient Memory Management for Large Language Model Serving with PagedAttention** | 2023 | [EffPagedAttn](https://arxiv.org/abs/2309.06180) |
| 21 | **vLLM** | **Effective Memory Management for Serving LLM with Heterogeneity** | 2025 | [EffLLMServ](https://arxiv.org/abs/2503.18292) |
| 22 | **GPU ISA & Architecture** | **Demystifying the Nvidia Ampere Architecture through Microbenchmarking and Instruction-level Analysis** | 2023 | [NvidiaAmpere](https://arxiv.org/abs/2208.11174) |
| 23 | **GPU ISA & Architecture** | **Cambricon: An Instruction Set Architecture for Neural Networks** | 2016 | [Cambricon](https://dl.acm.org/doi/10.1145/3331469) |
| 24 | **CUDA/ROCm** | **Optimizing sDTW for AMD GPUs** | 2024 | [AMDsDTW](https://arxiv.org/abs/2403.06931) |
| 25 | **TPU ISA & Architecture** | **TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings** | 2023 | [TPUs](https://arxiv.org/abs/2304.01433) |
| 26 | **TPU ISA & Architecture** | **MTIA: First Generation Silicon Targeting Meta's Recommendation Systems** | 2023 | [MTIA](https://dl.acm.org/doi/pdf/10.1145/3579371.3589348) |
| 27 | **TPU ISA & Architecture** | **Machine Learning Fleet Efficiency: Analyzing and Optimizing Large-Scale Google TPU Systems with ML Productivity Goodput** | 2016 | [MLFleet](https://arxiv.org/pdf/2502.06982) |
| 28 | **OpenVINO** | **OpenVINO Deep Learning Workbench: Comprehensive Analysis and Tuning of Neural Networks Inference** | 2019 | [Paper](https://openaccess.thecvf.com/content_ICCVW_2019/papers/SDL-CV/Gorbachev_OpenVINO_Deep_Learning_Workbench_Comprehensive_Analysis_and_Tuning_of_Neural_ICCVW_2019_paper.pdf) |
| 29 | **OpenVINO** | **Leveraging Speculative Sampling and KV-Cache Optimizations Together for Generative AI using OpenVINO** | 2023 | [Paper](https://arxiv.org/abs/2311.04951) |
| 30 | **Intel PlaidML** | **Stripe: Tensor Compilation via the Nested Polyhedral Model** | 2019 | [Paper](https://arxiv.org/abs/1903.06498) |
